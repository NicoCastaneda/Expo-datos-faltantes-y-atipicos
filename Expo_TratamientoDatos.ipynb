{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c9a8f1-3779-4dcc-9f14-5e36086c81ab",
   "metadata": {},
   "source": [
    "# Tratamiento de Datos Atípicos y Faltantes en Análisis de Datos\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "En la era del *big data*, la calidad de los datos se ha convertido en una de las cosas más importantes para construir modelos analíticos confiables. **Datos atípicos (outliers)** y **valores faltantes** representan dos de los desafíos más comunes que comprometen la integridad de los análisis, pudiendo distorsionar:\n",
    "- Estimaciones estadísticas\n",
    "- Patrones en modelos de machine learning\n",
    "- Conclusiones en investigación científica\n",
    "\n",
    "Estudios del [Instituto Nacional de Estándares y Tecnología (NIST)](https://www.nist.gov/) revelan que el **62% de los errores en modelos predictivos** se originan en problemas de calidad de datos no tratados. Además, regulaciones como el **GDPR (Artículo 5)** y estándares como **ISO 8000** exigen protocolos documentados para el manejo de datos incompletos o anómalos.\n",
    "\n",
    "**Objetivos de esta investigación**:\n",
    "1. Clasificar tipos de datos atípicos y faltantes\n",
    "2. Evaluar métodos de detección y tratamiento\n",
    "3. Proporcionar implementaciones prácticas en Python\n",
    "4. Establecer recomendaciones basadas en evidencia\n",
    "\n",
    "## 2. Marco Teórico\n",
    "\n",
    "### 2.1 Datos Atípicos (Outliers)\n",
    "\n",
    "**Definición**: Observaciones que se desvían significativamente del resto de la distribución (Hawkins, 1980).  \n",
    "**Clasificación**:\n",
    "- **Univariados**: Anomalías en una sola dimensión. Es decir, valores extremos en una variable.\n",
    "- **Multivariados**: Combinaciones inusuales entre variables. Por ejemplo, un alto ingreso con baja edad.\n",
    "\n",
    "**Algunas de las Causas**:\n",
    "- Errores de medición (sensores defectuosos)\n",
    "- Entradas legítimas pero extremas (transacciones fraudulentas)\n",
    "- Errores de procesamiento (decimales mal ubicados)\n",
    "\n",
    "**Métodos de Detección**:\n",
    "| Método         | Técnica                          | Ventajas                                                                 | Desventajas                                                                 | Casos de Uso Recomendados                                                                 |\n",
    "|----------------|----------------------------------|--------------------------------------------------------------------------|-----------------------------------------------------------------------------|------------------------------------------------------------------------------------------|\n",
    "| **Estadístico**| Z-score                         | - Fácil de implementar<br>- Rápido para datos unimodales                 | - Asume distribución normal<br>- No funciona bien con datos multimodales    | Datos con distribución cercana a la normal (ej: alturas, pesos)                          |\n",
    "|                | IQR (Rango Intercuartílico)     | - Robustez a outliers<br>- No depende de la distribución                 | - Solo detecta outliers univariados<br>- Menos sensible en datos dispersos  | Datos con colas pesadas o asimetría (ej: ingresos, tiempos de espera)                    |\n",
    "| **Visual**     | Boxplots                       | - Identificación intuitiva<br>- Útil para comparar distribuciones        | - Limitado a una o dos variables<br>- Subjetivo en la interpretación        | Análisis exploratorio inicial (ej: comparar distribuciones entre grupos)                 |\n",
    "|                | Gráficos de dispersión (Scatter)| - Detecta outliers multivariados<br>- Visualiza relaciones entre variables| - Difícil de interpretar con muchas variables<br>- Requiere datos limpios   | Detección de relaciones no lineales o agrupaciones (ej: análisis de clusters)            |\n",
    "| **Automático** | Isolation Forest               | - Efectivo en alta dimensión<br>- No requiere suposiciones de distribución| - Computacionalmente costoso<br>- Sensible a la elección de hiperparámetros | Detección de outliers en datasets grandes y complejos (ej: fraudes, fallos de equipos)   |\n",
    "|                | DBSCAN                         | - Detecta outliers y clusters<br>- Robustez a la forma de los clusters   | - Sensible a la elección de parámetros (eps, min_samples)<br>- Lento en grandes datasets | Datos con agrupaciones naturales (ej: segmentación de clientes, detección de anomalías)  |\n",
    "| **Híbrido**    | LOF (Local Outlier Factor)      | - Detecta outliers locales<br>- Útil en datos con densidad variable      | - Computacionalmente intensivo<br>- Difícil de interpretar en alta dimensión| Datos con patrones de densidad irregular (ej: detección de intrusos en redes)            |\n",
    "|                | One-Class SVM                  | - Efectivo para datos no lineales<br>- Útil cuando solo se tienen datos \"normales\" | - Requiere ajuste de hiperparámetros<br>- Lento en grandes datasets         | Detección de anomalías en sistemas de monitoreo (ej: fallos en máquinas, fraudes)        |\n",
    "\n",
    "**Técnicas de Tratamiento**:\n",
    "- **Eliminación**:\n",
    "Solo para errores comprobados, consiste en eliminar la observación. No es recomendable debido a la pérdida de información.\n",
    "Ejemplo: Eliminar valores negativos en una variable de edad.\n",
    "\n",
    "- **Transformación**:\n",
    "Aplicar funciones matemáticas (log, raíz cuadrada, etc.) para reducir el impacto de los outliers sin eliminarlos. Útil para datos con colas pesadas o asimetría.\n",
    "Ejemplo: Aplicar logaritmo a una variable de ingresos para reducir el efecto de valores extremos.\n",
    "\n",
    "- **Discretización**:\n",
    "Convertir valores continuos en intervalos o categorías. Reduce el efecto de outliers, pero puede causar pérdida de precisión.\n",
    "Ejemplo: Agrupar edades en rangos como \"18-25\", \"26-35\", etc.\n",
    "\n",
    "- **Winsorizing**:\n",
    "Reemplazar los valores extremos con los percentiles especificados (ej: 5% y 95%). Conserva la forma de la distribución sin eliminar datos.\n",
    "Ejemplo: Limitar los valores de una variable de precios al percentil 95%.\n",
    "\n",
    "- **Modelos Robustos**:\n",
    "Usar algoritmos menos sensibles a outliers, como Regresión Huber o Random Forests. No requiere modificar los datos, pero puede ser más costoso computacionalmente.\n",
    "Ejemplo: Usar Random Forests para predecir valores en un dataset con muchos outliers.\n",
    "\n",
    "### 2.2 Datos Faltantes\n",
    "\n",
    "Los datos faltantes son un problema común en conjuntos de datos reales y pueden afectar significativamente los resultados de los análisis. Según Rubin (1976), los datos faltantes se clasifican en tres categorías principales:\n",
    "\n",
    "1. **MCAR** (Missing Completely at Random): La probabilidad de que un valor falte es independiente de los datos observados y no observados.\n",
    "Ejemplo: Un sensor que falla aleatoriamente sin relación con las condiciones del entorno.\n",
    "2. **MAR** (Missing at Random): La probabilidad de que un valor falte depende de los datos observados.\n",
    "Ejemplo: En una encuesta de ingresos, es más probable que las personas con ingresos altos no respondan, pero esto depende de otras variables observadas (como la edad o el nivel educativo).  \n",
    "3. **MNAR** (Missing Not at Random): La probabilidad de que un valor falte depende de los datos no observados.  \n",
    "Ejemplo: En un estudio médico, los pacientes con síntomas graves pueden ser menos propensos a reportar su condición.\n",
    "\n",
    "**Patrones**:\n",
    "- Monotónico: Los datos faltantes siguen un patrón secuencial (ej: una encuesta abandonada después de cierta pregunta)\n",
    "- Arbitrario: Los datos faltantes no siguen un patrón claro (ej: fallos aleatorios en sensores).\n",
    "- Bloque: Un conjunto completo de variables falta para ciertas observaciones (ej: falta de registros en un período específico).\n",
    "\n",
    "#### Métodos de Manejo de Datos Faltantes\n",
    "##### 1. Eliminación\n",
    "- **Listwise Deletion**: Eliminar todas las observaciones con valores faltantes.  \n",
    "  **Ventaja**: Simple de implementar.  \n",
    "  **Desventaja**: Pérdida significativa de información si hay muchos datos faltantes.\n",
    "- **Pairwise Deletion**: Usar solo los datos disponibles para cada cálculo.  \n",
    "  **Ventaja**: Maximiza el uso de los datos.  \n",
    "  **Desventaja**: Puede introducir sesgos en los análisis.\n",
    "\n",
    "##### 2. Imputación Simple\n",
    "- **Media/Mediana/Moda**: Reemplazar los valores faltantes con la media, mediana o moda de la variable.  \n",
    "  **Ventaja**: Fácil de implementar.  \n",
    "  **Desventaja**: Subestima la varianza y distorsiona la distribución.\n",
    "- **Valor Constante**: Reemplazar con un valor fijo (ej: 0 o \"Desconocido\").  \n",
    "  **Ventaja**: Útil para variables categóricas.  \n",
    "  **Desventaja**: Puede introducir sesgos.\n",
    "\n",
    "##### 3. Imputación Avanzada\n",
    "- **MICE (Multiple Imputation by Chained Equations)**:  \n",
    "  Un método iterativo que usa regresiones para imputar valores faltantes.  \n",
    "  **Ventaja**: Captura la incertidumbre de la imputación.  \n",
    "  **Desventaja**: Computacionalmente costoso.\n",
    "  ```python\n",
    "  from sklearn.experimental import enable_iterative_imputer\n",
    "  from sklearn.impute import IterativeImputer\n",
    "  imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "  data_imputed = imputer.fit_transform(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
